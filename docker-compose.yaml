version: '3'

services:
  jupyter:
    build:
      context: .
      dockerfile: Dockerfile
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count : 'all'
              capabilities : [gpu]
    volumes:
      - ./:/llm
      - ./data/:/data/
      - ./cache/:/cache
    ports:
      - '8888:8888'
    environment:
      - OLLAMA_MODELS=/cache
      - OLLAMA_KEEP_ALIVE=60m
      - OLLAMA_NUM_PARALLEL=1 